{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TEMP CREDENTIALS\n",
    "\n",
    "\n",
    "ACCOUNT_ID = 'xxxxxx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "client = None\n",
    "client = boto3.client(\"quicksight\", region_name=\"ap-southeast-2\")\n",
    "#client = session.client(\"quicksight\", region_name=\"ap-southeast-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Quicksight Assets in an account\n",
    "\n",
    "## Looking at the following (excludes new items like Stories)\n",
    "- Data Sources\n",
    "- Data Sets\n",
    "- Analysis\n",
    "- Dashboards\n",
    "- Old Users within QS (not federated)\n",
    "- Old Groups within QS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start with Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of data sources from AWS QuickSight\n",
    "list_data_sources_response = client.list_data_sources(\n",
    "    AwsAccountId=ACCOUNT_ID,\n",
    ")\n",
    "list_data_sources_response\n",
    "\n",
    "# Create pandas DataFrame from data sources response\n",
    "data_source_df = pd.DataFrame(list_data_sources_response[\"DataSources\"])\n",
    "\n",
    "# Convert datetime columns to date format\n",
    "date_columns = data_source_df.select_dtypes(include=['datetime64[ns, UTC]']).columns\n",
    "for date_column in date_columns:\n",
    "    data_source_df[date_column] = data_source_df[date_column].dt.date\n",
    "    \n",
    "# Initialize empty list to store data source permissions\n",
    "data_source_permission_list = []\n",
    "\n",
    "# Iterate through data sources and get permissions for each\n",
    "for index, row in data_source_df.iterrows():\n",
    "    data_source_id = row[\"DataSourceId\"]\n",
    "    data_source_name = row[\"Name\"]\n",
    "\n",
    "    # Get permissions for current data source\n",
    "    describe_data_sources_perm_response = client.describe_data_source_permissions(\n",
    "        AwsAccountId=ACCOUNT_ID,\n",
    "        DataSourceId=data_source_id\n",
    "    )\n",
    "\n",
    "    # Extract permission details and add to list\n",
    "    for permission_entry in describe_data_sources_perm_response[\"Permissions\"]:\n",
    "        data_source_permission_list.append({\n",
    "                \"DataSourceId\": data_source_id,\n",
    "                \"DataSourceName\": data_source_name,\n",
    "                \"Principal\": permission_entry[\"Principal\"],\n",
    "                \"Actions\": permission_entry[\"Actions\"]\n",
    "            })\n",
    "\n",
    "# Create DataFrame from permissions list\n",
    "data_source_permission_df = pd.DataFrame(data_source_permission_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting details for dataset 30fae72e-0a7a-4ef9-bcae-ad35511f04c6: SKIPPING Data Source for this - MOST LIKELY ITS CSV / FILE UPLOAD ?\n"
     ]
    }
   ],
   "source": [
    "# Get list of all datasets in the account\n",
    "list_data_sets_response = client.list_data_sets(\n",
    "    AwsAccountId=ACCOUNT_ID,\n",
    ")\n",
    "\n",
    "# Convert dataset list to pandas DataFrame\n",
    "data_set_df = pd.DataFrame(list_data_sets_response[\"DataSetSummaries\"])\n",
    "\n",
    "# Convert datetime columns to date format\n",
    "date_columns = data_set_df.select_dtypes(include=['datetime64[ns, UTC]']).columns\n",
    "for date_column in date_columns:\n",
    "    data_set_df[date_column] = data_set_df[date_column].dt.date\n",
    "\n",
    "# Initialize lists to store datasource and permission info\n",
    "dataset_datasource_list = []\n",
    "dataset_permission_list = []\n",
    "\n",
    "# Iterate through each dataset to get details\n",
    "for index, row in data_set_df.iterrows():\n",
    "    data_set_id = row[\"DataSetId\"]\n",
    "    data_set_name = row[\"Name\"]\n",
    "\n",
    "    # Get detailed information about the dataset\n",
    "    try:\n",
    "        data_set_describe_response = client.describe_data_set(\n",
    "            AwsAccountId=ACCOUNT_ID,\n",
    "            DataSetId=data_set_id\n",
    "        )\n",
    "        \n",
    "        # Extract datasource information from physical table mappings\n",
    "        for source in data_set_describe_response[\"DataSet\"][\"PhysicalTableMap\"]:\n",
    "            for inner_source, details in data_set_describe_response[\"DataSet\"][\"PhysicalTableMap\"][source].items():\n",
    "                dataset_datasource_list.append({\n",
    "                    \"DataSetId\": data_set_id,\n",
    "                    \"DataSourceArn\": details[\"DataSourceArn\"]\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting details for dataset {data_set_id}: SKIPPING Data Source for this - MOST LIKELY ITS CSV / FILE UPLOAD ?\")\n",
    "\n",
    "\n",
    "    # Get permissions associated with the dataset\n",
    "    describe_data_set_perm_response = client.describe_data_set_permissions(\n",
    "        AwsAccountId=ACCOUNT_ID,\n",
    "        DataSetId=data_set_id\n",
    "    )\n",
    "\n",
    "    # Extract permission details\n",
    "    for permission_entry in describe_data_set_perm_response[\"Permissions\"]:\n",
    "        dataset_permission_list.append({\n",
    "                \"DataSetId\": data_set_id,\n",
    "                \"DataSetName\": data_set_name,\n",
    "                \"Principal\": permission_entry[\"Principal\"],\n",
    "                \"Actions\": permission_entry[\"Actions\"]\n",
    "            })\n",
    "        \n",
    "# Convert datasource list to DataFrame\n",
    "dataset_datasource_df = pd.DataFrame(dataset_datasource_list)\n",
    "\n",
    "# Convert permissions list to DataFrame\n",
    "dataset_permission_df = pd.DataFrame(dataset_permission_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all analyses for the account\n",
    "list_analyses_response = client.list_analyses(\n",
    "    AwsAccountId=ACCOUNT_ID,\n",
    ")\n",
    "# Convert analyses list to pandas dataframe\n",
    "analyses_df = pd.DataFrame(list_analyses_response[\"AnalysisSummaryList\"])\n",
    "\n",
    "# Initialize empty lists to store datasources and permissions\n",
    "analysis_datasource_list = []\n",
    "analysis_permission_list = []\n",
    "\n",
    "# Convert datetime columns to date format\n",
    "date_columns = analyses_df.select_dtypes(include=['datetime64[ns, UTC]']).columns\n",
    "for date_column in date_columns:\n",
    "    analyses_df[date_column] = analyses_df[date_column].dt.date\n",
    "\n",
    "# Iterate through each analysis to get datasources and permissions\n",
    "for index, row in analyses_df.iterrows():\n",
    "\n",
    "    analyses_id = row[\"AnalysisId\"]\n",
    "    analysis_name = row[\"Name\"]\n",
    "\n",
    "    # Get detailed information about the analysis\n",
    "    analyses_describe_response = client.describe_analysis(\n",
    "        AwsAccountId=ACCOUNT_ID,\n",
    "        AnalysisId=analyses_id\n",
    "    )\n",
    "\n",
    "    # Extract and store datasource information\n",
    "    for dataset in analyses_describe_response[\"Analysis\"][\"DataSetArns\"]:\n",
    "        analysis_datasource_list.append(\n",
    "            {'AnalysisId': analyses_id,\n",
    "            'DataSetArn': dataset\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Get permissions for the analysis\n",
    "    describe_analysis_perm_response = client.describe_analysis_permissions(\n",
    "        AwsAccountId=ACCOUNT_ID,\n",
    "        AnalysisId=analyses_id\n",
    "    )\n",
    "\n",
    "    # Extract and store permission information\n",
    "    for permission_entry in describe_data_set_perm_response[\"Permissions\"]:\n",
    "        analysis_permission_list.append({\n",
    "                \"AnalysisId\": analyses_id,\n",
    "                \"AnalysisName\": analysis_name,\n",
    "                \"Principal\": permission_entry[\"Principal\"],\n",
    "                \"Actions\": permission_entry[\"Actions\"]\n",
    "            })\n",
    "        \n",
    "# Convert datasource and permission lists to dataframes\n",
    "analysis_datasource_df = pd.DataFrame(analysis_datasource_list)\n",
    "analysis_permission_df = pd.DataFrame(dataset_permission_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all dashboards for the account\n",
    "list_dashboards_response = client.list_dashboards(\n",
    "    AwsAccountId=ACCOUNT_ID,\n",
    ")\n",
    "# Convert dashboard list to pandas dataframe\n",
    "dashboard_df = pd.DataFrame(list_dashboards_response[\"DashboardSummaryList\"])\n",
    "\n",
    "# Convert datetime columns to date format\n",
    "date_columns = dashboard_df.select_dtypes(include=['datetime64[ns, UTC]']).columns\n",
    "for date_column in date_columns:\n",
    "    dashboard_df[date_column] = dashboard_df[date_column].dt.date\n",
    "\n",
    "# Initialize lists to store dashboard analysis and permissions\n",
    "dashboard_analysis_list = []\n",
    "dashboard_permission_list = []\n",
    "\n",
    "# Iterate through each dashboard to get additional details\n",
    "for index, row in dashboard_df.iterrows():\n",
    "    dashboard_id = row[\"DashboardId\"]\n",
    "    \n",
    "    # Get detailed dashboard information\n",
    "    dashboard_describe_response = client.describe_dashboard(\n",
    "        AwsAccountId=ACCOUNT_ID,\n",
    "        DashboardId=dashboard_id\n",
    "    )\n",
    "\n",
    "    # Extract and store analysis ARN for the dashboard\n",
    "    dashboard_analysis_list.append(\n",
    "            {'DashboardId': dashboard_id,\n",
    "            'AnalysisArn': dashboard_describe_response[\"Dashboard\"][\"Version\"][\"SourceEntityArn\"]\n",
    "            }\n",
    "    )\n",
    "\n",
    "    # Get dashboard permissions\n",
    "    describe_dashboard_perm_response = client.describe_dashboard_permissions(\n",
    "        AwsAccountId=ACCOUNT_ID,\n",
    "        DashboardId=dashboard_id\n",
    "    )\n",
    "\n",
    "    # Extract and store permission details for each principal\n",
    "    for permission_entry in describe_dashboard_perm_response[\"Permissions\"]:\n",
    "        dashboard_permission_list.append({\n",
    "                \"DashboardId\": dashboard_id,\n",
    "                \"Principal\": permission_entry[\"Principal\"],\n",
    "                \"Actions\": permission_entry[\"Actions\"]\n",
    "            })\n",
    "\n",
    "# Convert analysis and permissions lists to pandas dataframes\n",
    "dashboard_analysis_df = pd.DataFrame(dashboard_analysis_list)\n",
    "dashboard_permission_df = pd.DataFrame(dashboard_permission_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicksight Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call QuickSight API to get list of users in the account\n",
    "list_users_response = client.list_users(\n",
    "    AwsAccountId=ACCOUNT_ID,\n",
    "    Namespace='default'\n",
    ")\n",
    "\n",
    "# Convert the user list response to a pandas DataFrame for easier manipulation\n",
    "users_df = pd.DataFrame(list_users_response[\"UserList\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicksight Groups and Memberships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all groups in the default namespace\n",
    "list_groups_response = client.list_groups(\n",
    "    AwsAccountId=ACCOUNT_ID,\n",
    "    Namespace='default'\n",
    ")\n",
    "\n",
    "# Convert groups list to pandas DataFrame\n",
    "groups_df = pd.DataFrame(list_groups_response[\"GroupList\"])\n",
    "\n",
    "# Initialize empty list to store group membership details\n",
    "group_membership_list = []\n",
    "\n",
    "# Iterate through each group\n",
    "for index, row in groups_df.iterrows():\n",
    "    group_name = row[\"GroupName\"]\n",
    "    \n",
    "    # Get list of members for current group\n",
    "    group_membership_response = client.list_group_memberships(\n",
    "        AwsAccountId=ACCOUNT_ID,\n",
    "        GroupName=group_name,\n",
    "        Namespace='default' )\n",
    "    \n",
    "    \n",
    "    # For each member in the group, add their details to the list\n",
    "    for group_membership_entry in group_membership_response[\"GroupMemberList\"]:\n",
    "        group_membership_list.append(\n",
    "            {'GroupName': group_name,\n",
    "             'MemberArn': group_membership_entry[\"Arn\"],\n",
    "            'MemberName': group_membership_entry[\"MemberName\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert membership list to pandas DataFrame\n",
    "group_membership_df = pd.DataFrame(group_membership_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an excel file with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file created at quicksight_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the Excel file\n",
    "file_path = 'quicksight_analysis.xlsx'\n",
    "\n",
    "# Write each DataFrame to a different sheet in the Excel file\n",
    "with pd.ExcelWriter(file_path) as writer:\n",
    "    data_source_df.to_excel(writer, sheet_name='DataSources', index=False)\n",
    "    data_source_permission_df.to_excel(writer, sheet_name='DataSourcePermissions', index=False)\n",
    "    data_set_df.to_excel(writer, sheet_name='DataSets', index=False)\n",
    "    dataset_datasource_df.to_excel(writer, sheet_name='DataSet_DataSource', index=False)\n",
    "    dataset_permission_df.to_excel(writer, sheet_name='DataSetPermissions', index=False)\n",
    "    analyses_df.to_excel(writer, sheet_name='Analyses', index=False)\n",
    "    analysis_datasource_df.to_excel(writer, sheet_name='Analysis_DataSource', index=False)\n",
    "    analysis_permission_df.to_excel(writer, sheet_name='AnalysisPermissions', index=False)\n",
    "    dashboard_df.to_excel(writer, sheet_name='Dashboards', index=False)\n",
    "    dashboard_analysis_df.to_excel(writer, sheet_name='Dashboard_Analysis', index=False)\n",
    "    dashboard_permission_df.to_excel(writer, sheet_name='DashboardPermissions', index=False)\n",
    "    users_df.to_excel(writer, sheet_name='Users', index=False)\n",
    "    groups_df.to_excel(writer, sheet_name='Groups', index=False)\n",
    "    group_membership_df.to_excel(writer, sheet_name='GroupMembership', index=False)\n",
    "\n",
    "print(f\"Excel file created at {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
